{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3c4d33f",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Yelp Reviews\n",
    "\n",
    "**Author**: Logan Ash  \n",
    "**Date**: 2025-04-29\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**Research Question**: What is the overall sentiment of Yelp reviews for coffee shops in New York, NY?\n",
    "\n",
    "In this notebook, we will:\n",
    "1. Collect at least 60 reviews using the Yelp Fusion API.  \n",
    "2. Clean the review text.  \n",
    "3. Perform sentiment analysis using:\n",
    "   - TextBlob's default sentiment analyzer  \n",
    "   - TextBlob's NaiveBayesAnalyzer  \n",
    "4. Visualize the sentiment distributions with donut charts.  \n",
    "5. Remove stop words and generate a WordCloud of the top 20 words.  \n",
    "\n",
    "This approach will help us compare analyzers and understand common themes in customer feedback.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cebe948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install required packages if not already installed\n",
    "# !pip install yelpapi textblob nltk wordcloud matplotlib nbformat\n",
    "\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468d516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Yelp Fusion API Key here\n",
    "API_KEY = os.getenv('YELP_API_KEY') or 'YOUR_YELP_API_KEY'\n",
    "HEADERS = {'Authorization': f'Bearer {API_KEY}'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e74ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch business IDs for 'coffee' in New York, NY\n",
    "business_ids = []\n",
    "search_url = 'https://api.yelp.com/v3/businesses/search'\n",
    "params = {'term': 'coffee', 'location': 'New York, NY', 'limit': 20}\n",
    "response = requests.get(search_url, headers=HEADERS, params=params).json()\n",
    "for biz in response.get('businesses', []):\n",
    "    business_ids.append(biz['id'])\n",
    "\n",
    "# Collect up to 60+ reviews (3 per business)\n",
    "reviews = []\n",
    "review_url = 'https://api.yelp.com/v3/businesses/{}/reviews'\n",
    "for biz_id in business_ids:\n",
    "    resp = requests.get(review_url.format(biz_id), headers=HEADERS).json()\n",
    "    for r in resp.get('reviews', []):\n",
    "        reviews.append(r['text'])\n",
    "\n",
    "print(f\"Collected {len(reviews)} reviews\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4965952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text: remove non-alphanumeric, lowercase, strip\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^A-Za-z0-9 ]+', '', text)\n",
    "    return text.lower().strip()\n",
    "\n",
    "cleaned_reviews = [clean_text(r) for r in reviews]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc267355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sentiment with TextBlob default analyzer\n",
    "counts_default = {'positive': 0, 'negative': 0, 'neutral': 0}\n",
    "for txt in cleaned_reviews:\n",
    "    pol = TextBlob(txt).sentiment.polarity\n",
    "    if pol > 0:\n",
    "        counts_default['positive'] += 1\n",
    "    elif pol < 0:\n",
    "        counts_default['negative'] += 1\n",
    "    else:\n",
    "        counts_default['neutral'] += 1\n",
    "\n",
    "# Donut chart\n",
    "labels = list(counts_default.keys())\n",
    "sizes = list(counts_default.values())\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, wedgeprops={'width':0.3})\n",
    "ax.set_title('Sentiment Distribution (TextBlob Default)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc37e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sentiment with NaiveBayesAnalyzer\n",
    "counts_nb = {'positive': 0, 'negative': 0}\n",
    "for txt in cleaned_reviews:\n",
    "    blob = TextBlob(txt, analyzer=NaiveBayesAnalyzer())\n",
    "    classification = blob.sentiment.classification\n",
    "    counts_nb[classification] += 1\n",
    "\n",
    "# Donut chart for NB\n",
    "labels = list(counts_nb.keys())\n",
    "sizes = list(counts_nb.values())\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, wedgeprops={'width':0.3})\n",
    "ax.set_title('Sentiment Distribution (NaiveBayesAnalyzer)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f331de4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NLTK stopwords and filter\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "all_words = ' '.join(cleaned_reviews)\n",
    "filtered = ' '.join(w for w in all_words.split() if w not in stop_words)\n",
    "\n",
    "# Generate WordCloud\n",
    "wc = WordCloud(width=800, height=400, max_words=20).generate(filtered)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Top 20 Words WordCloud')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab2c3c9",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- The default TextBlob analyzer classified reviews as positive, negative, and neutral, providing a nuanced view.\n",
    "- The NaiveBayesAnalyzer only labels reviews as positive or negative, resulting in no neutrals.\n",
    "- The WordCloud highlights frequent themes (e.g., espresso, service, ambiance), which align with the sentiment distributions.\n",
    "\n",
    "Through this comparison, we see different sentiment tools offer varied insights. The WordCloud also surfaces common customer feedback topics.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
